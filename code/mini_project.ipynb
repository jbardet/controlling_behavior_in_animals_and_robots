{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a275a6e",
   "metadata": {},
   "source": [
    "# CBAR Miniproject : code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import for the project\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random\n",
    "import heapq\n",
    "import statsmodels as sm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from behavelet import wavelet_transform\n",
    "import scipy.stats as st\n",
    "from scipy.stats import zscore\n",
    "from itertools import combinations\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first load the neural data with pandas and look at it\n",
    "neural_data = pd.read_pickle('data/COBAR_neural.pkl')\n",
    "neural_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot traces from individual neurons \n",
    "# We will use random number generation to choose few neurons to plot as we don't want to plot all the 123 neurons\n",
    "# We've chosen here to plot 5 neurons\n",
    "\n",
    "nb_trials = 12\n",
    "trials_name = ['trial_' + str(i+1) for i in range(nb_trials)]\n",
    "plot_scaling_factor = 5000\n",
    "\n",
    "for j in range(5):\n",
    "    random_neuron = random.randrange(122)\n",
    "    neuron = \"neuron_\"+str(random_neuron)\n",
    "\n",
    "    ytick = []\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "    for i in range(nb_trials):   \n",
    "        ax.plot(neural_data[neural_data.index.get_level_values(\"Trial\")==0][\"t\"], i*plot_scaling_factor + neural_data[neuron][neural_data.index.get_level_values(\"Trial\")==i].values - neural_data[neuron][neural_data.index.get_level_values(\"Trial\")==i].values[0])\n",
    "        ytick.append(i*plot_scaling_factor)\n",
    "\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(\"Fluorescence [-]\")\n",
    "    ax.set_title(f'Fluorescence data of neuron {random_neuron} across trials')\n",
    "\n",
    "    plt.yticks(np.array(ytick), trials_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47018bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we see here and in the traces, a good summary of a neuron would be his standard deviation as it does \n",
    "# show whether the neuron is active during the trials.\n",
    "#Let's find the neurons with the maximal standard deviation\n",
    "maximums = []\n",
    "maximum_values = []\n",
    "for neuron in neural_data : \n",
    "    if not neuron == 't' : \n",
    "        maximums.append(neural_data.groupby('Trial').std().nlargest(1, neuron).index.values[0])\n",
    "        maximum_values.append(neural_data.groupby('Trial').std().nlargest(1, neuron)[neuron].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287aa658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And plot them\n",
    "ten_max_values = heapq.nlargest(10, maximum_values)\n",
    "maximum_neuron = []\n",
    "maximum_trial = []\n",
    "for value in ten_max_values :\n",
    "    maximum_neuron.append(maximum_values.index(value))\n",
    "    maximum_trial.append(maximums[maximum_values.index(value)])\n",
    "\n",
    "\n",
    "ytick = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "i=0\n",
    "for index in maximum_neuron:\n",
    "    neuron = neural_data[neural_data.columns[index+1]].name\n",
    "    temp = np.copy(neural_data[neural_data.index.get_level_values('Trial')==maximums[index]][neuron])\n",
    "    ax.plot(neural_data[neural_data.index.get_level_values('Trial')==maximums[index]]['t'], i*5000 + temp - temp[0], label = neuron)\n",
    "    ytick.append(i*5000)\n",
    "    i=i+1\n",
    "\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.set_ylabel(\"Fluorescence [-]\")\n",
    "ax.set_title(f'Fluorescence data of the ten most active neurons across trials')\n",
    "\n",
    "index_name = ['neuron_' + str(maximum_neuron[i]) +'_trial_'+ str(maximum_trial[i]) for i in range(len(maximum_neuron))]\n",
    "plt.yticks(np.array(ytick), index_name)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2955277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now load the behavioral data with pandas and look at it\n",
    "behav_data = pd.read_pickle('data/COBAR_behaviour_incl_manual_corrected.pkl')\n",
    "behav_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd79b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see the differences between \n",
    "print(len(behav_data['Prediction'].unique()), len(behav_data['Manual'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that joints and angles are represented in the columns 2 to 134.\n",
    "behav_data.columns[2:134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eddcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot traces from individual joints or angles \n",
    "# We've chosen here to plot 5 angles or joints randomly\n",
    "\n",
    "nb_trials = 12\n",
    "trials_name = ['trial_' + str(i+1) for i in range(nb_trials)]\n",
    "\n",
    "for j in range(5) :\n",
    "    random_mvmt = random.randrange(133)\n",
    "    mvmt = behav_data.columns[random_mvmt+2]\n",
    "\n",
    "    ytick = []\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "    for i in range(nb_trials):   \n",
    "        ax.plot(behav_data[behav_data.index.get_level_values(\"Trial\")==0][\"t\"], i*plot_scaling_factor + (behav_data[mvmt][behav_data.index.get_level_values(\"Trial\")==i].values - behav_data[mvmt][behav_data.index.get_level_values(\"Trial\")==i].values[0])*plot_scaling_factor/2.1)\n",
    "        ytick.append(i*plot_scaling_factor)\n",
    "\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(\"Joint angle [rad] / position [mm]\")\n",
    "    ax.set_title(f'Joint angle or position of {mvmt} across trials')\n",
    "\n",
    "    plt.yticks(np.array(ytick), trials_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce57c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The minimum of the fluorescence would not be a good baseline thus we will compute a moving average \n",
    "# with help of the pandas Series function rolling with a window size of 10. \n",
    "\n",
    "# Here we computed the baseline for each neuron for each trial and store it in a new dataframe \n",
    "\n",
    "neuron_names = ['neuron_' + str(i) for i in range(122)]\n",
    "trials = ['trial_' + str(i) for i in range(12)]\n",
    "\n",
    "baseline = pd.DataFrame(index = trials, columns =neuron_names)\n",
    "\n",
    "for neuron in neuron_names :\n",
    "    for i in range(12) :\n",
    "        minimum = np.min(neural_data[neuron][neural_data.index.get_level_values(\"Trial\")==i].rolling(10).min())\n",
    "        baseline[neuron][trials[i]] = minimum\n",
    "\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the noise, we plot a neuron zoomed in a specific interval of time\n",
    "\n",
    "plt.plot(neural_data[neural_data.index.get_level_values(\"Trial\")==0]['t'].iloc[0:500], neural_data['neuron_0'][neural_data.index.get_level_values(\"Trial\")==0].iloc[0:500])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Fluorescence [-]\")\n",
    "plt.title(\"Noise visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare different sigma values for the gaussian filter (0, 3, 6)\n",
    "\n",
    "gaussian_f1 = np.copy(neural_data[\"neuron_0\"][neural_data.index.get_level_values(\"Trial\")==0].iloc[0:500])\n",
    "gaussian_f2 = np.copy(neural_data[\"neuron_0\"][neural_data.index.get_level_values(\"Trial\")==0].iloc[0:500])\n",
    "gaussian_f3 = np.copy(neural_data[\"neuron_0\"][neural_data.index.get_level_values(\"Trial\")==0].iloc[0:500])\n",
    "\n",
    "plt.plot(neural_data[neural_data.index.get_level_values(\"Trial\")==0][\"t\"].iloc[0:500], gaussian_f1, label = \"original data\")\n",
    "plt.plot(neural_data[neural_data.index.get_level_values(\"Trial\")==0][\"t\"].iloc[0:500], gaussian_filter1d(gaussian_f2, 3), label = \"Gaussian filter, σ=3\")\n",
    "plt.plot(neural_data[neural_data.index.get_level_values(\"Trial\")==0][\"t\"].iloc[0:500], gaussian_filter1d(gaussian_f3, 6), label = \"Gaussian filter, σ=6\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Fluorescence [-]\")\n",
    "plt.title(\"Noise filering\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the plot we can see that a sigma of 6 is enough to approximate the noisy data so we\n",
    "# will use this filter to denoise the data.\n",
    "\n",
    "# Apply gaussian filter of sigma = 6 to the data\n",
    "neural_data_filtered = neural_data.copy()\n",
    "\n",
    "columns = neural_data_filtered.columns.values.tolist()\n",
    "neurons = columns[1:]\n",
    "for neuron in neurons : \n",
    "    for i in range(12) :\n",
    "        neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i] = gaussian_filter1d(neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i], sigma=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replot the first the non-modified data, then the denoised one\n",
    "\n",
    "nb_trials = 12\n",
    "trials_name = ['trial_' + str(i+1) for i in range(nb_trials)]\n",
    "plot_scaling_factor = 5000\n",
    "\n",
    "for j in range(5):\n",
    "    random_neuron = random.randrange(122)\n",
    "    neuron = \"neuron_\"+str(random_neuron)\n",
    "\n",
    "    ytick = []\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "    for i in range(nb_trials):   \n",
    "        ax.plot(neural_data[neural_data.index.get_level_values(\"Trial\")==0][\"t\"], i*plot_scaling_factor + neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].values - neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].values[0])\n",
    "        ytick.append(i*plot_scaling_factor)\n",
    "\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(\"Fluorescence [-]\")\n",
    "    ax.set_title(f'Fluorescence data of neuron {random_neuron} across trials')\n",
    "\n",
    "    plt.yticks(np.array(ytick), trials_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f8ae9",
   "metadata": {},
   "source": [
    "## Neuronal data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data_filtered\n",
    "# 123 neurons\n",
    "# 12 trials\n",
    "# 4040 time points per trial\n",
    "# 48480 total time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_data :\n",
    "# 123 neurons\n",
    "# 12 trials\n",
    "# 4040 time points per trial\n",
    "# 48480 total time points\n",
    "\n",
    "# PCA : each neuron as a feature, each time point as a sample, all trials at once\n",
    "\n",
    "# X1 : (n_samples, n_features)\n",
    "# size : (48480*123)\n",
    "# 123 components\n",
    "# 48480 samples\n",
    "\n",
    "pca = PCA(n_components=123)\n",
    "X1 = pca.fit_transform(neural_data_filtered.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot result\n",
    "nb_trials = 12\n",
    "plot_scaling_factor = 15000\n",
    "\n",
    "for j in range(5) : # the 5 first components\n",
    "    ytick = []\n",
    "    fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "    for i in range(nb_trials):   \n",
    "        ax.plot(neural_data_filtered[neural_data_filtered.index.get_level_values(\"Trial\")==0][\"t\"], i*plot_scaling_factor + X1[i*4040:(i+1)*4040, j])\n",
    "        ytick.append(X1[i*4040, j] + i*plot_scaling_factor)\n",
    "\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(\"Component [p.d.u.]\")\n",
    "    ax.set_title(f\"PCA component {j}\")\n",
    "\n",
    "    plt.yticks(np.array(ytick), trials_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result PCA\n",
    "loadings = pca.components_\n",
    "# in the loadings matrix, we have :\n",
    "# each column a neuron\n",
    "# each line a component\n",
    "\n",
    "n = 5\n",
    "sorted_array = np.sort(loadings, None)\n",
    "print(f\"loadings {loadings}\")\n",
    "print(f\"max value {loadings.max():2.2}\")\n",
    "print(f\"n biggest values:\")\n",
    "for i in range(n):\n",
    "    print(f\"\\t{sorted_array[-1-i]:2.2}\")\n",
    "print(f\"Biggest neurons contribs:\")\n",
    "for i in range(n):\n",
    "    print(f\"\\t{np.where(loadings == sorted_array[-1-i])}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "pos = ax.imshow(loadings)\n",
    "fig.colorbar(pos, ax = ax)\n",
    "plt.xlabel(\"Principal component 1\")\n",
    "plt.ylabel(\"Principal component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings are the covariances/correlations between the original variables and the unit-scaled components.\n",
    "print(f\"Explained variance (by component) :\\n{pca.explained_variance_ratio_}\")\n",
    "print(f\"Explained variance (cumulated) :\\n{np.cumsum(pca.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219aa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the point density of te 2 firsts components that explain 69% of the total variance\n",
    "xy = np.vstack([X1[:,0], X1[:,1]])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(X1[:,0], X1[:,1], c=z, s=100)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"Density-coded scatter-plot of the first two components of the PCA results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try to cluster the data with KMeans\n",
    "\n",
    "model_km_mean = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans = model_km_mean.fit_predict(X1[:,0:2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(X1[:,0], X1[:,1], c=kmeans)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"k-means of PCA results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the t-SNE on the PCA\n",
    "tsne= TSNE(n_components=2)\n",
    "Y1 = tsne.fit_transform(X1)\n",
    "\n",
    "# Y1 :\n",
    "# size : (48480*2)\n",
    "# 48480 samples\n",
    "# 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc53879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the point density\n",
    "xy = np.vstack([Y1[:,0], Y1[:,1]])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(Y1[:,0], Y1[:,1], c=z, s=100)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"Scatter-plot of TSNE results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_data :\n",
    "# 123 neurons\n",
    "# 12 trials\n",
    "# 4040 time points per trial\n",
    "# 48480 total time points\n",
    "\n",
    "# PCA : this time, each neuron as a sample, each (averaged) time point as a feature\n",
    "\n",
    "# x2 : (n_samples, n_features)\n",
    "# size : (123*12)\n",
    "# 123 samples\n",
    "# 12 components\n",
    "\n",
    "neural_data_mean = np.zeros((12,123))\n",
    "for i in range(12):\n",
    "    neural_data_mean[i,:] = neural_data_filtered.iloc[i*4040:(i+1)*4040, 1:].mean(axis = 0)\n",
    "\n",
    "pca = PCA(n_components=12)\n",
    "X2 = pca.fit_transform(neural_data_mean.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d79065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also try TSNE on this data \n",
    "\n",
    "tsne_mean = TSNE(n_components=2)\n",
    "X2_mean = tsne_mean.fit_transform(neural_data_mean.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = tsne.fit_transform(X2)\n",
    "\n",
    "# Y2 :\n",
    "# size : (123*2)\n",
    "# 123 samples\n",
    "# 2 components\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([Y2[:,0], Y2[:,1]])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(Y2[:,0], Y2[:,1], c=z, s=100)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"Scatter-plot of PCA results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f044462",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2_mean = tsne.fit_transform(X2_mean)\n",
    "\n",
    "# Y2 :\n",
    "# size : (123*2)\n",
    "# 123 samples\n",
    "# 2 components\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([Y2_mean[:,0], Y2_mean[:,1]])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(Y2_mean[:,0], Y2_mean[:,1], c=z, s=100)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"Scatter-plot of TSNE results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I used the TSNE components to distinguish datapoints\n",
    "\n",
    "model_km_mean = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans = model_km_mean.fit_predict(Y2_mean)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(Y2_mean[:,0], Y2_mean[:,1], c=kmeans)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"k-means of TSNE results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2173909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the result above we can plot neural trace depending on group \n",
    "\n",
    "nb_trials = 12\n",
    "trials_name = ['trial_' + str(i+1) for i in range(nb_trials)]\n",
    "\n",
    "for i in np.where(model_km_mean.labels_ == 2)[0] :\n",
    "    neuron = 'neuron_'+str(i)\n",
    "    ytick = []\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "    for i in range(nb_trials):   \n",
    "        ax.plot(neural_data_filtered[neural_data_filtered.index.get_level_values(\"Trial\")==0]['t'], i*2500 + neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].values, label = neuron)\n",
    "        ytick.append(neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].iloc[0] + i*2500)\n",
    "    ax.set_ylabel('Fluorescence (a.u)')\n",
    "    ax.set_xlabel('Time (sec)')\n",
    "    ax.set_title(f'Fluorescence data of {neuron} across trials')\n",
    "\n",
    "    plt.yticks(np.array(ytick), trials_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fa1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the result above we can plot neural trace depending on group \n",
    "\n",
    "nb_trials = 12\n",
    "trials_name = ['trial_' + str(i+1) for i in range(nb_trials)]\n",
    "\n",
    "for i in np.where(model_km_mean.labels_ == 0)[0] :\n",
    "    neuron = 'neuron_'+str(i)\n",
    "    ytick = []\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "    for i in range(nb_trials):   \n",
    "        ax.plot(neural_data_filtered[neural_data_filtered.index.get_level_values(\"Trial\")==0]['t'], i*2500 + neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].values, label = neuron)\n",
    "        ytick.append(neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].iloc[0] + i*2500)\n",
    "    ax.set_ylabel('Fluorescence (a.u)')\n",
    "    ax.set_xlabel('Time (sec)')\n",
    "    ax.set_title(f'Fluorescence data of {neuron} across trials')\n",
    "\n",
    "    plt.yticks(np.array(ytick), trials_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the result above we can plot neural trace depending on group \n",
    "\n",
    "nb_trials = 12\n",
    "trials_name = ['trial_' + str(i+1) for i in range(nb_trials)]\n",
    "\n",
    "for i in np.where(model_km_mean.labels_ == 1)[0] :\n",
    "    neuron = 'neuron_'+str(i)\n",
    "    ytick = []\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "    for i in range(nb_trials):   \n",
    "        ax.plot(neural_data_filtered[neural_data_filtered.index.get_level_values(\"Trial\")==0]['t'], i*2500 + neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].values, label = neuron)\n",
    "        ytick.append(neural_data_filtered[neuron][neural_data_filtered.index.get_level_values(\"Trial\")==i].iloc[0] + i*2500)\n",
    "    ax.set_ylabel('Fluorescence (a.u)')\n",
    "    ax.set_xlabel('Time (sec)')\n",
    "    ax.set_title(f'Fluorescence data of {neuron} across trials')\n",
    "\n",
    "    plt.yticks(np.array(ytick), trials_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977dca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see if GMM clusters the data correctly\n",
    "model_gm_mean = GaussianMixture(n_components=3, random_state=0)\n",
    "gm_mean = model_gm_mean.fit_predict(Y2_mean)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(Y2_mean[:,0], Y2_mean[:,1], c=gm_mean)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"GMM of TSNE results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see if KMeans clusters the data correctly\n",
    "model_km = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans = model_km.fit_predict(Y2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(Y2[:,0], Y2[:,1], c=kmeans)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"k-means of PCA results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see if GMM clusters the data correctly\n",
    "model_gm = GaussianMixture(n_components=3, random_state=0)\n",
    "gm = model_gm.fit_predict(Y2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "ax.scatter(Y2[:,0], Y2[:,1], c=gm)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"GMM of PCA results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare whether Kmeans on mean data and normal data gives same result\n",
    "comparison = model_km_mean.labels_ == gm_mean\n",
    "indices = [i for i, x in enumerate(comparison.tolist()) if x == False]\n",
    "indices #neurons that are differently classified between the 2 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare whether GMM on mean data and normal data gives same result\n",
    "comparison = model_km.labels_ == gm\n",
    "indices = [i for i, x in enumerate(comparison.tolist()) if x == False]\n",
    "indices #neurons that are differently classified between the 2 methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20d4dc",
   "metadata": {},
   "source": [
    "## Identifying features of behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaca58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract data joint\n",
    "behav_data_joint = behav_data.filter(regex=\"joint\")\n",
    "# Extract data angle\n",
    "behav_data_angle = behav_data.filter(regex=\"angle\")\n",
    "# Extract by trial\n",
    "nb_trials = 12\n",
    "nb_time = behav_data_joint[behav_data.index.get_level_values(\"Trial\")==1].shape[0]\n",
    "nb_feature_joint = behav_data_joint[behav_data.index.get_level_values(\"Trial\")==1].shape[1]\n",
    "nb_feature_angle = behav_data_angle[behav_data.index.get_level_values(\"Trial\")==1].shape[1]\n",
    "\n",
    "print(f'Nb time : {nb_time}, Nb feature joint : {nb_feature_joint}, Nb feature angle : {nb_feature_angle}')\n",
    "\n",
    "joint_data = np.zeros((nb_trials, nb_time, nb_feature_joint))\n",
    "angle_data = np.zeros((nb_trials, nb_time, nb_feature_angle))\n",
    "for i in range(nb_trials):\n",
    "    joint_data[i,:,:] = behav_data_joint[behav_data.index.get_level_values(\"Trial\")==i].to_numpy()\n",
    "    angle_data[i,:,:] = behav_data_angle[behav_data.index.get_level_values(\"Trial\")==i].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75759d27",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ae4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA for joint pose\n",
    "nb_components_joint = 13\n",
    "output_pca_joint = np.zeros((nb_trials, nb_time, nb_components_joint))\n",
    "for i in range(nb_trials):\n",
    "    pca_joint = PCA(n_components=nb_components_joint)\n",
    "    output_pca_joint[i,:,:] = pca_joint.fit_transform(joint_data[i,:,:])\n",
    "    print(f\"Trail {i}, Nb components : {nb_components_joint}, Variance : {sum(pca_joint.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA for joint angle\n",
    "nb_components_angle = 17\n",
    "output_pca_angle = np.zeros((nb_trials, nb_time, nb_components_angle))\n",
    "for i in range(nb_trials):\n",
    "    pca_joint = PCA(n_components=nb_components_angle)\n",
    "    output_pca_angle[i,:,:] = pca_joint.fit_transform(angle_data[i,:,:])\n",
    "    print(f\"Trail {i}, Nb components : {nb_components_angle}, Variance : {sum(pca_joint.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8668a",
   "metadata": {},
   "source": [
    "### Wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet for Joint\n",
    "# Parameters\n",
    "nb_freqs=25\n",
    "sample_frequency = 100\n",
    "min_frequency = 1\n",
    "max_frequency = 50\n",
    "\n",
    "# Result matrix\n",
    "freqs_joint = np.zeros((nb_trials, nb_freqs))\n",
    "power_joint = np.zeros((nb_trials, nb_time))\n",
    "wavelet_joint = np.zeros((nb_trials, nb_time, nb_components_joint*nb_freqs))\n",
    "\n",
    "# Compute Wavelet\n",
    "for i in range(nb_trials):\n",
    "    print(f'Joint : Trial {i+1} / {nb_trials}')\n",
    "    temp1, temp2, temp3 = wavelet_transform(output_pca_joint[i,:,:], n_freqs=nb_freqs, fsample=sample_frequency, fmin=min_frequency, fmax=max_frequency)\n",
    "    freqs_joint[i,:] = temp1\n",
    "    power_joint[i,:] = temp2\n",
    "    wavelet_joint[i,:,:] = temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06831d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet for Angle\n",
    "# Parameters\n",
    "nb_freqs=25\n",
    "sample_frequency = 100\n",
    "min_frequency = 1\n",
    "max_frequency = 50\n",
    "\n",
    "# Result matrix\n",
    "freqs_angle = np.zeros((nb_trials, nb_freqs))\n",
    "power_angle = np.zeros((nb_trials, nb_time))\n",
    "wavelet_angle = np.zeros((nb_trials, nb_time, nb_components_angle*nb_freqs))\n",
    "\n",
    "for i in range(nb_trials):\n",
    "    print(f'Angle : Trial {i+1} / {nb_trials}')\n",
    "    temp4, temp5, temp6 = wavelet_transform(output_pca_angle[i,:,:], n_freqs=nb_freqs, fsample=sample_frequency, fmin=min_frequency, fmax=max_frequency)\n",
    "    freqs_angle[i,:] = temp4\n",
    "    power_angle[i,:] = temp5\n",
    "    wavelet_angle[i,:,:] = temp6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318d766",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE for joint form PCA\n",
    "nb_components_tsne = 2\n",
    "tsne_joint_pca = np.zeros((nb_trials, nb_time, nb_components_tsne))\n",
    "for i in range(nb_trials):\n",
    "    print(f'Joint : Trial {i+1} / {nb_trials}')\n",
    "    tsne = TSNE(n_components=nb_components_tsne)\n",
    "    tsne_joint_pca[i,:,:] = tsne.fit_transform(output_pca_joint[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE for joint form wavelete\n",
    "nb_components_tsne = 2\n",
    "tsne_joint_wavelete = np.zeros((nb_trials, nb_time, nb_components_tsne))\n",
    "for i in range(nb_trials):\n",
    "    print(f'Joint : Trial {i+1} / {nb_trials}')\n",
    "    tsne = TSNE(n_components=nb_components_tsne)\n",
    "    tsne_joint_wavelete[i,:,:] = tsne.fit_transform(wavelet_joint[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcef2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE for angle form PCA\n",
    "nb_components_tsne = 2\n",
    "tsne_angle_pca = np.zeros((nb_trials, nb_time, nb_components_tsne))\n",
    "for i in range(nb_trials):\n",
    "    print(f'Joint : Trial {i+1} / {nb_trials}')\n",
    "    tsne = TSNE(n_components=nb_components_tsne)\n",
    "    tsne_angle_pca[i,:,:] = tsne.fit_transform(output_pca_angle[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE for angle form wavelete\n",
    "nb_components_tsne = 2\n",
    "tsne_angle_wavelete = np.zeros((nb_trials, nb_time, nb_components_tsne))\n",
    "for i in range(nb_trials):\n",
    "    print(f'Joint : Trial {i+1} / {nb_trials}')\n",
    "    tsne = TSNE(n_components=nb_components_tsne)\n",
    "    tsne_angle_wavelete[i,:,:] = tsne.fit_transform(wavelet_angle[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1315f9",
   "metadata": {},
   "source": [
    "### Plot result\n",
    "#### Joint\n",
    "From PCA -> Wavelet, PCA -> t-SNE, PCA -> Wavelet -> t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Wavelete for Joint\n",
    "fig, ax = plt.subplots(nrows = nb_trials, ncols=1 ,figsize = (12,100), sharex = True)\n",
    "for nb in range(nb_trials):\n",
    "    ax[nb].imshow(wavelet_joint[nb,:,:].T,aspect=30)\n",
    "    ax[nb].set_ylabel('Component')\n",
    "    ax[nb].set_xlabel('time')\n",
    "    ax[nb].set_title(f'Trial {nb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot form t-SNE for joint form PCA\n",
    "for i in range(nb_trials):\n",
    "    # Peform the kernel density estimate\n",
    "    x = tsne_joint_pca[i,:,0]\n",
    "    y = tsne_joint_pca[i,:,1]\n",
    "    values = np.vstack([x, y])\n",
    "    z = st.gaussian_kde(values)(values)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.scatter(x,y,c=z, s=100)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} : 2D Gaussian Kernel density estimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot form t-SNE for joint form wavelete\n",
    "for i in range(nb_trials):\n",
    "    # Peform the kernel density estimate\n",
    "    x = tsne_joint_wavelete[i,:,0]\n",
    "    y = tsne_joint_wavelete[i,:,1]\n",
    "    values = np.vstack([x, y])\n",
    "    z = st.gaussian_kde(values)(values)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.scatter(x,y,c=z, s=100)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} : 2D Gaussian Kernel density estimation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68f15d",
   "metadata": {},
   "source": [
    "#### Angle\n",
    "From PCA -> Wavelet, PCA -> t-SNE, PCA -> Wavelet -> t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7345187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Wavelete for angle\n",
    "fig, ax = plt.subplots(nrows = nb_trials, ncols=1 ,figsize = (12,100), sharex = True)\n",
    "for nb in range(nb_trials):\n",
    "    ax[nb].imshow(wavelet_angle[nb,:,:].T,aspect=30)\n",
    "    ax[nb].set_ylabel('Component')\n",
    "    ax[nb].set_xlabel('time')\n",
    "    ax[nb].set_title(f'Trial {nb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot form t-SNE for angle form PCA\n",
    "for i in range(nb_trials):\n",
    "    # Peform the kernel density estimate\n",
    "    x = tsne_angle_pca[i,:,0]\n",
    "    y = tsne_angle_pca[i,:,1]\n",
    "    values = np.vstack([x, y])\n",
    "    z = st.gaussian_kde(values)(values)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.scatter(x,y,c=z, s=100)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} : 2D Gaussian Kernel density estimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot form t-SNE for angle form wavelete\n",
    "for i in range(nb_trials):\n",
    "    # Peform the kernel density estimate\n",
    "    x = tsne_angle_wavelete[i,:,0]\n",
    "    y = tsne_angle_wavelete[i,:,1]\n",
    "    values = np.vstack([x, y])\n",
    "    z = st.gaussian_kde(values)(values)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.scatter(x,y,c=z, s=100)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} : 2D Gaussian Kernel density estimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try to plot different timepoints in different color\n",
    "for i in range(nb_trials):\n",
    "    # Peform the kernel density estimate\n",
    "    x = tsne_angle_pca[i,:,0]\n",
    "    y = tsne_angle_pca[i,:,1]\n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = st.gaussian_kde(values)\n",
    "    f = np.reshape(kernel(positions).T, xx.shape)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(x)))\n",
    "    plt.scatter(x, y, color=colors)\n",
    "    #ax.set_xlim(xmin, xmax)\n",
    "    #ax.set_ylim(ymin, ymax)\n",
    "    #cfset = ax.contourf(xx, yy, f, cmap='coolwarm')\n",
    "    #ax.imshow(np.rot90(f), cmap='coolwarm', extent=[xmin, xmax, ymin, ymax])\n",
    "    #cset = ax.contour(xx, yy, f, colors='k')\n",
    "    #ax.clabel(cset, inline=1, fontsize=10)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(f'Trial {i} : 2D Gaussian Kernel density estimation')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f476b6a",
   "metadata": {},
   "source": [
    "# Part 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first look at our labels \n",
    "labels_unique = behav_data['Manual'].unique()\n",
    "print(labels_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfc457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look whether they are different from the predictions one\n",
    "comparison = behav_data['Manual'] == behav_data['Prediction']\n",
    "print(f'We have {len([i for i, x in enumerate(comparison.tolist()) if x == True])} behavioral match between predictions and manual labeling')\n",
    "print(f'And {len([i for i, x in enumerate(comparison.tolist()) if x == False])} behavioral differences between predictions and manual labeling')\n",
    "\n",
    "indices = [i for i, x in enumerate(comparison.tolist()) if x == False]\n",
    "names = []\n",
    "count = []\n",
    "for indice in indices : \n",
    "    pred = behav_data.iloc[indice]['Prediction']\n",
    "    man = behav_data.iloc[indice]['Manual']\n",
    "    if pred+\"/\"+man in names : \n",
    "        count[names.index(pred+\"/\"+man)] = count[names.index(pred+\"/\"+man)] + 1\n",
    "    else : \n",
    "        names.append(pred+\"/\"+man)\n",
    "        count.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The differences between manual and prediction labels\n",
    "for i in range(len(names)) :\n",
    "    print(names[i], '->' ,count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d474e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first plot the tsne joint PCA\n",
    "for i in range(nb_trials):\n",
    "    x = tsne_joint_pca[i,:,0]\n",
    "    y = tsne_joint_pca[i,:,1]\n",
    "    \n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    \n",
    "    labels = behav_data[behav_data.index.get_level_values(\"Trial\")==i]['Manual']\n",
    "    dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple'}\n",
    "    label = labels.replace(dic_colors)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} :n')\n",
    "    \n",
    "    plt.scatter(x,y, s=0.5, c=label.values, label=dic_colors)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144da1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then the tsne of joint wavelete \n",
    "for i in range(nb_trials):\n",
    "    x = tsne_joint_wavelete[i,:,0]\n",
    "    y = tsne_joint_wavelete[i,:,1]\n",
    "    \n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    \n",
    "    labels = behav_data[behav_data.index.get_level_values(\"Trial\")==i]['Manual']\n",
    "    dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple'}\n",
    "    label = labels.replace(dic_colors)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} :n')\n",
    "    \n",
    "    plt.scatter(x,y, s=0.5, c=label.values, label=dic_colors)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then the tsne of angle pca \n",
    "for i in range(nb_trials):\n",
    "    x = tsne_angle_pca[i,:,0]\n",
    "    y = tsne_angle_pca[i,:,1]\n",
    "    \n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    \n",
    "    labels = behav_data[behav_data.index.get_level_values(\"Trial\")==i]['Manual']\n",
    "    dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple'}\n",
    "    label = labels.replace(dic_colors)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} :n')\n",
    "    \n",
    "    plt.scatter(x,y, s=0.5, c=label.values, label=dic_colors)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83464c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then the tsne of angle wavelete\n",
    "for i in range(nb_trials):\n",
    "    x = tsne_angle_wavelete[i,:,0]\n",
    "    y = tsne_angle_wavelete[i,:,1]\n",
    "    \n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    \n",
    "    labels = behav_data[behav_data.index.get_level_values(\"Trial\")==i]['Manual']\n",
    "    dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple'}\n",
    "    label = labels.replace(dic_colors)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} :n')\n",
    "    \n",
    "    plt.scatter(x,y, s=0.5, c=label.values, label=dic_colors)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0820f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ellipse(gmm, ax) : \n",
    "    colors = ['black', 'red', 'blue', 'green', 'purple']\n",
    "    for n, color in enumerate(colors): \n",
    "        covariances = gmm.covariances_[n][:2, :2]\n",
    "        v, w = np.linalg.eigh(covariances)\n",
    "        u = w[0] / np.linalg.norm(w[0])\n",
    "        angle = np.arctan2(u[1], u[0])\n",
    "        angle = 180 * angle / np.pi  # convert to degrees\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        ell = mpl.patches.Ellipse(gmm.means_[n, :2], v[0], v[1],\n",
    "                                      180 + angle, color=color)\n",
    "        ell.set_clip_box(ax.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        ax.add_artist(ell)\n",
    "        ax.set_aspect('equal', 'datalim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's try to cluster the data with a Gaussian mixture model as KMeans would not cluster circle-shaped data.\n",
    "# We use a mixture of 5 components as we have 5 categories \n",
    "\n",
    "for i in range(nb_trials):\n",
    "    x = tsne_joint_pca[i,:,0]\n",
    "    y = tsne_joint_pca[i,:,1]\n",
    "\n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    \n",
    "    labels = behav_data[behav_data.index.get_level_values(\"Trial\")==i]['Manual']\n",
    "    dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple'}\n",
    "    label = labels.replace(dic_colors)\n",
    "\n",
    "    gmm = GaussianMixture(n_components=5, max_iter=100)\n",
    "    x_label = gmm.fit_predict(tsne_joint_pca[i,:])\n",
    "    #print(gmm.means_)\n",
    "    #print('then')\n",
    "    #print(gmm.covariances_)\n",
    "    #print(\"Score : \")\n",
    "    #print(gmm.score(tsne_joint_pca[i,:]))\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} :n')\n",
    "    \n",
    "    plt.scatter(x,y, s=0.5, c=label.values, label=dic_colors)\n",
    "    draw_ellipse(gmm, ax)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's try to cluster the data with a KMeans.\n",
    "# We use a mixture of 5 components as we have 5 categories \n",
    "\n",
    "x = tsne_angle_wavelete[11,:,0]\n",
    "y = tsne_angle_wavelete[11,:,1]\n",
    "\n",
    "xmin, xmax = min(x), max(x)\n",
    "ymin, ymax = min(y), max(y)\n",
    "    \n",
    "labels = behav_data[behav_data.index.get_level_values(\"Trial\")==11]['Manual']\n",
    "dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple'}\n",
    "label = labels.replace(dic_colors)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, max_iter=100)\n",
    "x_label = kmeans.fit_predict(tsne_angle_wavelete[11,:])\n",
    "    \n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.gca()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.title(f'Trial {i} :n')\n",
    "    \n",
    "#plt.scatter(x,y, s=0.5, c=label.values, label=dic_colors)\n",
    "plt.scatter(x,y, s=0.5, c=x_label, label=dic_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From : https://medium.com/@plog397/functions-to-plot-kmeans-hierarchical-and-dbscan-clustering-c4146ed69744\n",
    "\n",
    "def dbscan(X, eps, min_samples):\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    db.fit(X)\n",
    "    y_pred = db.fit_predict(X)\n",
    "    plt.scatter(X[:,0], X[:,1],c=y_pred, cmap='Paired', alpha=0.5)\n",
    "    plt.title(\"DBSCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can clearly see that Kmeans does not properly cluster the data, thus we can try to use \n",
    "# Density-based spatial clustering (DBSCAN) that is a better method for nonlinear clusters. \n",
    "\n",
    "for i in range(nb_trials):\n",
    "    x = tsne_angle_wavelete[i,:,0]\n",
    "    y = tsne_angle_wavelete[i,:,1]\n",
    "\n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    \n",
    "    labels = behav_data[behav_data.index.get_level_values(\"Trial\")==i]['Manual']\n",
    "    dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple'}\n",
    "    label = labels.replace(dic_colors)\n",
    "    \n",
    "    dbscan(tsne_angle_wavelete[i,:], 0.1, 1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title(f'Trial {i} :n')\n",
    "    plt.scatter(x,y, s=0.5, c=label.values, label=dic_colors)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb3e25",
   "metadata": {},
   "source": [
    "# Part 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d061820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use all joint angles, 25 wavelet features, 1 to 50 Hz wavelet, no PCA\n",
    "\n",
    "# Parameters\n",
    "nb_freqs=25\n",
    "sample_frequency = 100\n",
    "min_frequency = 1\n",
    "max_frequency = 50  \n",
    "nb_components_angle = 42\n",
    "    \n",
    "# Angle\n",
    "freqs_angle = np.zeros((nb_trials, nb_freqs))\n",
    "power_angle = np.zeros((nb_trials, nb_time))\n",
    "wavelet_angle = np.zeros((nb_trials, nb_time, nb_components_angle*nb_freqs))\n",
    "\n",
    "for i in range(nb_trials):\n",
    "    print(f'Angle : Trial {i+1} / {nb_trials}')\n",
    "    temp4, temp5, temp6 = wavelet_transform(angle_data[i,:,:], n_freqs=nb_freqs, fsample=sample_frequency, fmin=min_frequency, fmax=max_frequency)\n",
    "    freqs_angle[i,:] = temp4\n",
    "    power_angle[i,:] = temp5\n",
    "    wavelet_angle[i,:,:] = temp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then train with random forest on the data that we split first between train and test set\n",
    "X = np.reshape(wavelet_angle, (302400, 1050))\n",
    "y = behav_data['Manual']\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=70, oob_score=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_prediction = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2804f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the accuracy of manual prediction\n",
    "y_train_pred = rfc.predict(X_train)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n",
    "print('Score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And then the prediction from predicted labeling\n",
    "y_pred=rfc.predict(X)\n",
    "y=behav_data['Prediction']\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the most important predicting features of the classifier\n",
    "print(rfc.feature_importances_.argsort()[0:10]%25)\n",
    "print(behav_data_angle[behav_data_angle.columns[23]])\n",
    "print(behav_data_angle[behav_data_angle.columns[22]])\n",
    "print(behav_data_angle[behav_data_angle.columns[24]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33bdab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the number of differences between the manual labeling and our prediction\n",
    "\n",
    "y_differences = rfc.predict(X)\n",
    "comparison = y == y_differences\n",
    "comparison_data = behav_data.iloc[[i for i, x in enumerate(comparison.tolist()) if x == False]]\n",
    "\n",
    "comparison_2 = comparison_data['Manual'] == comparison_data['Prediction']\n",
    "print(f'We have {len([i for i, x in enumerate(comparison_2.tolist()) if x == True])} behavioral match between predictions and manual labeling')\n",
    "print(f'And {len([i for i, x in enumerate(comparison_2.tolist()) if x == False])} behavioral differences between predictions and manual labeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c32b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's to compare predicted data now : \n",
    "y_pred = behav_data['Prediction']\n",
    "y_pred_prediction = rfc.predict(X)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_pred_prediction))\n",
    "\n",
    "comparison = y_pred == y_pred_prediction\n",
    "comparison_data = behav_data.iloc[[i for i, x in enumerate(comparison.tolist()) if x == False]]\n",
    "\n",
    "comparison_2 = comparison_data['Manual'] == comparison_data['Prediction']\n",
    "print(f'We have {len([i for i, x in enumerate(comparison_2.tolist()) if x == True])} behavioral match between predictions and manual labeling')\n",
    "print(f'And {len([i for i, x in enumerate(comparison_2.tolist()) if x == False])} behavioral differences between predictions and manual labeling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398fc163",
   "metadata": {},
   "source": [
    "## Combining neural & behavioural data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3825b",
   "metadata": {},
   "source": [
    "### Downsampling the behavioral data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf472d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to down-sample the data (from Braun's notebook)\n",
    "\n",
    "# these two functions are just wrappers around the numpy functions to apply them across dimension 0 only\n",
    "def reduce_mean(values):\n",
    "    return np.mean(values, axis=0)\n",
    "def reduce_std(values):\n",
    "    return np.std(values, axis=0)\n",
    "def reduce_behaviour(values):\n",
    "    \"\"\"\n",
    "    this is just a sketch for how to reduce behavioural classes. \n",
    "    It picks whatever behaviour occurs the most.\n",
    "    Try to make this more stable, for example by handling the case when two behaviours are equally likely.\n",
    "    You might also want to include a certainty threshold, \n",
    "    e.g. 3/4 of the behaviour frames have to be labelled the same way, otherwise it is None and the data is excluded\n",
    "    \"\"\"\n",
    "    unique_values, N_per_unique = np.unique(values, return_counts=True)\n",
    "    i_max = np.argmax(N_per_unique)\n",
    "    return unique_values[i_max]\n",
    "\n",
    "def reduce_during_2p_frame(twop_index, values, function=reduce_mean):\n",
    "    \"\"\"\n",
    "    Reduces all values occuring during the acquisition of a\n",
    "    two-photon imaging frame to a single value using the `function` given by the user.\n",
    "    Parameters\n",
    "    ----------\n",
    "    twop_index : numpy array\n",
    "        1d array holding frame indices of one trial.\n",
    "    values : numpy array\n",
    "        Values upsampled to the frequency of ThorSync,\n",
    "        i.e. 1D numpy array of the same length as\n",
    "        `frame_counter` or 2D numpy array of the same length.\n",
    "    function : function\n",
    "        Function used to reduce the value,\n",
    "        e.g. np.mean for 1D variables\n",
    "    Returns\n",
    "    -------\n",
    "    reduced : numpy array\n",
    "        Numpy array with value for each two-photon imaging frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(twop_index) != len(values):\n",
    "        raise ValueError(\"twop_index and values need to have the same length.\")\n",
    "    if len(values.shape) == 1:\n",
    "        values = np.expand_dims(values, axis=1)\n",
    "        squeeze = True\n",
    "    else:\n",
    "        squeeze = False\n",
    "    N_samples, N_variables = values.shape\n",
    "    \n",
    "    index_unique = np.unique(twop_index)\n",
    "    index_unique = np.delete(index_unique, index_unique==-9223372036854775808)\n",
    "    \n",
    "    dtype = values.dtype\n",
    "    if np.issubdtype(dtype, np.number):\n",
    "        dtype = np.float\n",
    "    else:\n",
    "        dtype = np.object\n",
    "    reduced = np.empty((len(index_unique), N_variables), dtype=dtype)\n",
    "\n",
    "    for i, index in enumerate(index_unique):\n",
    "        reduced[i] = function(values[twop_index==index, :])\n",
    "\n",
    "    return np.squeeze(reduced) if squeeze else reduced\n",
    "\n",
    "def plot_neuron_data(neuron_list, nb_plot):\n",
    "    for k in range(nb_plot):\n",
    "        neuron_label = neuron_list[k]\n",
    "        fig, ax = plt.subplots(6,2, figsize=(15, 15))\n",
    "        fig.suptitle(f'Plot for neuron {neuron_label}')\n",
    "        for i in range(2):\n",
    "            for j in range(6):\n",
    "                idx = j+(6*i)\n",
    "                # 28, 62, 93\n",
    "                neuron = 100*(neural_df_s.loc[(210301, \"J1xCI9\", 1, idx), \"neuron_\" + str(neuron_label)]-610)/610\n",
    "\n",
    "                ax[j,i].plot(neural_df_s.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron, label=(\"neuron_\" + str(neuron_label)))\n",
    "                ax[j,i].fill_between(neural_df_s.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], find_behavior(neural_df_s[idx*4040:idx*4040+4040], 'walking'),alpha = 0.5,label=\"walking\")\n",
    "                ax[j,i].fill_between(neural_df_s.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], find_behavior(neural_df_s[idx*4040:idx*4040+4040], 'resting'), alpha = 0.5,label=\"resting\")\n",
    "                ax[j,i].set_xlabel(\"t (s)\")\n",
    "                ax[j,i].set_ylabel(\"$\\% \\Delta F/F$\")\n",
    "                ax[j,i].legend()\n",
    "\n",
    "                ax[j,i].spines['left'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "                # turn off the right spine/ticks\n",
    "                ax[j,i].spines['right'].set_color('none')\n",
    "                ax[j,i].yaxis.tick_left()\n",
    "\n",
    "                # set the y-spine\n",
    "                ax[j,i].spines['bottom'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "                # turn off the top spine/ticks\n",
    "                ax[j,i].spines['top'].set_color('none')\n",
    "                ax[j,i].xaxis.tick_bottom()\n",
    "                ax[j,i].set_title(f'Trial {idx}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cabcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now down-sample our data first by only down-sampling the numerical data, and only then the categorical ones\n",
    "# We will create a dataframe per trial here and then concatenate to a single dataframe\n",
    "columns_numerical = behav_data.columns.to_list()\n",
    "columns_numerical.remove('Prediction')\n",
    "columns_numerical.remove('Manual')\n",
    "columns_numerical.remove('twop_index')\n",
    "\n",
    "columns_categorical = ['Prediction', 'Manual']\n",
    "dfs = []\n",
    "for i in range(12) :\n",
    "    twop_index = behav_data.loc[(210301, \"J1xCI9\", 1, i), \"twop_index\"].to_numpy()\n",
    "    values_numerical = behav_data.loc[(210301, \"J1xCI9\", 1, i)][columns_numerical].to_numpy()\n",
    "    reduced_numerical = reduce_during_2p_frame(twop_index, values_numerical, function=reduce_mean)\n",
    "\n",
    "    values_categorical = behav_data.loc[(210301, \"J1xCI9\", 1, i)][columns_categorical].to_numpy()\n",
    "    reduced_categorical = reduce_during_2p_frame(twop_index, values_categorical, function=reduce_behaviour)\n",
    "    df = pd.DataFrame(reduced_numerical, columns = columns_numerical)\n",
    "    df[columns_categorical] = reduced_categorical\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1813dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now put all that in a single dataframe\n",
    "behav_data_r = pd.concat(dfs, keys=[0,1,2,3,4,5,6,7,8,9,10,11], axis=0, names=['Trial', 'Frame'])\n",
    "behav_data_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e5125",
   "metadata": {},
   "source": [
    "###  Identifying correlations of individual neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first divide the behavioral data by states \n",
    "\n",
    "states = behav_data_r['Manual'].unique()\n",
    "print(f'Possible states are :{states}')\n",
    "\n",
    "resting_state = behav_data_r.loc[behav_data_r['Manual'] == 'resting']\n",
    "print(f'Resting state df length : {len(resting_state)}')\n",
    "walking_state = behav_data_r.loc[behav_data_r['Manual'] == 'walking']\n",
    "print(f'Walking state df length : {len(walking_state)}')\n",
    "anterior_grooming_state = behav_data_r.loc[behav_data_r['Manual'] == 'anterior_grooming']\n",
    "print(f'Anterior grooming state df length : {len(anterior_grooming_state)}')\n",
    "antennal_grooming_state = behav_data_r.loc[behav_data_r['Manual'] == 'antennal_grooming']\n",
    "print(f'Antennal grooming state df length : {len(antennal_grooming_state)}')\n",
    "foreleg_grooming_state = behav_data_r.loc[behav_data_r['Manual'] == 'foreleg_grooming']\n",
    "print(f'Foreleg grooming state df length : {len(foreleg_grooming_state)}')\n",
    "abdominal_grooming_state = behav_data_r.loc[behav_data_r['Manual'] == 'abdominal_grooming']\n",
    "print(f'Abdominal grooming state df length : {len(abdominal_grooming_state)}')\n",
    "abdominal_pushing_state = behav_data_r.loc[behav_data_r['Manual'] == 'abdominal_pushing']\n",
    "print(f'Abdominal pushing state df length : {len(abdominal_pushing_state)}')\n",
    "posterior_grooming_state = behav_data_r.loc[behav_data_r['Manual'] == 'posterior_grooming']\n",
    "print(f'Posterior grooming state df length : {len(posterior_grooming_state)}')\n",
    "hindleg_grooming_state = behav_data_r.loc[behav_data_r['Manual'] == 'hindleg_grooming']\n",
    "print(f'Hindleg grooming state df length : {len(hindleg_grooming_state)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8770a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now look at mean neuron activity during behavior\n",
    "resting_means = []\n",
    "walking_means = []\n",
    "anterior_grooming_means = []\n",
    "antennal_grooming_means= []\n",
    "foreleg_grooming_means=[]\n",
    "abdominal_grooming_means = []\n",
    "abdominal_pushing_means = []\n",
    "posterior_grooming_means = []\n",
    "hindleg_grooming_means = []\n",
    "\n",
    "for neuron in neural_data_filtered.columns :\n",
    "    if neuron =='t' : pass\n",
    "    else : \n",
    "        \n",
    "        resting_mean = np.mean(neural_data_filtered.iloc[resting_state.index.get_level_values(level=1)][neuron])\n",
    "        resting_means.append(resting_mean)\n",
    "        walking_mean = np.mean(neural_data_filtered.iloc[walking_state.index.get_level_values(level=1)][neuron])\n",
    "        walking_means.append(walking_mean)\n",
    "        anterior_grooming_mean = np.mean(neural_data_filtered.iloc[anterior_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        anterior_grooming_means.append(anterior_grooming_mean)\n",
    "        antennal_grooming_mean = np.mean(neural_data_filtered.iloc[antennal_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        antennal_grooming_means.append(antennal_grooming_mean)\n",
    "        foreleg_grooming_mean = np.mean(neural_data_filtered.iloc[foreleg_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        foreleg_grooming_means.append(foreleg_grooming_mean)\n",
    "        abdominal_grooming_mean = np.mean(neural_data_filtered.iloc[abdominal_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        abdominal_grooming_means.append(abdominal_grooming_mean)\n",
    "        abdominal_pushing_mean = np.mean(neural_data_filtered.iloc[abdominal_pushing_state.index.get_level_values(level=1)][neuron])\n",
    "        abdominal_pushing_means.append(abdominal_pushing_mean)\n",
    "        posterior_grooming_mean = np.mean(neural_data_filtered.iloc[posterior_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        posterior_grooming_means.append(posterior_grooming_mean)\n",
    "        hindleg_grooming_mean = np.mean(neural_data_filtered.iloc[hindleg_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        hindleg_grooming_means.append(hindleg_grooming_mean)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.boxplot([resting_means, walking_means, anterior_grooming_means,antennal_grooming_means, foreleg_grooming_means, \\\n",
    "             abdominal_grooming_means,abdominal_pushing_means,posterior_grooming_means,hindleg_grooming_means])\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7,8,9], states.tolist())\n",
    "plt.ylabel(\"mean $\\% \\Delta F/F$ neuron\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEt's plot a matrix with the neurons and their value for behavior\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.matshow([resting_means, walking_means, anterior_grooming_means,antennal_grooming_means,foreleg_grooming_means, \\\n",
    "             abdominal_grooming_means,abdominal_pushing_means,posterior_grooming_means,hindleg_grooming_means], fignum=1, aspect='auto')\n",
    "plt.yticks([0, 1, 2, 3, 4, 5, 6,7,8], states.tolist())\n",
    "plt.xlabel(\"neurons number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now try to standardize the data before plotting\n",
    "neural_df_s = neural_data_filtered.copy()\n",
    "\n",
    "for neuron in neural_data_filtered.columns :\n",
    "    if neuron =='t' : pass\n",
    "    else : \n",
    "        neural_df_s[neuron] = zscore(neural_data_filtered[neuron])\n",
    "        \n",
    "neural_df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ce1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To test the difference of means we need to add a column which is the manual behavior to the neural dataframe\n",
    "neural_df_s['Manual'] = behav_data_r['Manual'].values\n",
    "neural_df_s = neural_df_s.astype({\"Manual\":str})\n",
    "neural_df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7accbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have this dataset we can plot behaviors from neuronal analysis\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "\n",
    "labels = neural_df_s['Manual']\n",
    "dic_colors = {'resting': 'black', 'walking': 'red', 'anterior_grooming':'blue', 'abdominal_pushing':'green', 'posterior_grooming':'purple', 'antennal_grooming' : 'yellow', 'foreleg_grooming' : 'pink', 'abdominal_grooming':'grey', 'hindleg_grooming' : 'brown'}\n",
    "label = labels.replace(dic_colors)\n",
    "    \n",
    "ax.scatter(X1[:,0], X1[:,1], s=100, c=label.values, label=dic_colors)\n",
    "ax.set_xlabel(\"Component 0 [p.d.u.]\")\n",
    "ax.set_ylabel(\"Component 1 [p.d.u.]\")\n",
    "ax.set_title(f\"Density-coded scatter-plot of the first two components of the PCA results\")\n",
    "plt.legend()\n",
    "plt.savefig('figures/pca_2_neuron_label.eps', format='eps')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now look at mean neuron activity during behavior\n",
    "resting_means = []\n",
    "walking_means = []\n",
    "anterior_grooming_means = []\n",
    "antennal_grooming_means= []\n",
    "foreleg_grooming_means=[]\n",
    "abdominal_grooming_means = []\n",
    "abdominal_pushing_means = []\n",
    "posterior_grooming_means = []\n",
    "hindleg_grooming_means = []\n",
    "resting_stds = []\n",
    "walking_stds = []\n",
    "anterior_grooming_stds = []\n",
    "antennal_grooming_stds= []\n",
    "foreleg_grooming_stds=[]\n",
    "abdominal_grooming_stds = []\n",
    "abdominal_pushing_stds = []\n",
    "posterior_grooming_stds = []\n",
    "hindleg_grooming_stds = []\n",
    "\n",
    "# And we will test whether each neuron has a significant mean difference in activation depending on the state\n",
    "tukey_test = []\n",
    "\n",
    "for neuron in neural_df_s.columns :\n",
    "    if neuron =='t' or neuron =='Manual' : pass\n",
    "    else : \n",
    "        #ANOVA + TUKEY test in a new dataframe\n",
    "        formula = f'{neuron}~C(Manual)'\n",
    "        model = ols(formula, data=neural_df_s).fit()\n",
    "        aov_table = anova_lm(model)\n",
    "        if aov_table['PR(>F)'][0] <0.0005 : \n",
    "            comparison = MultiComparison(neural_df_s[neuron], neural_df_s['Manual'])\n",
    "            comparison_results = comparison.tukeyhsd()\n",
    "            tukey_test.append(comparison_results.reject)\n",
    "        \n",
    "        resting_mean = np.mean(neural_df_s.iloc[resting_state.index.get_level_values(level=1)][neuron])\n",
    "        resting_std= np.std(neural_df_s.iloc[resting_state.index.get_level_values(level=1)][neuron])\n",
    "        resting_means.append(resting_mean)\n",
    "        resting_stds.append(resting_std)\n",
    "        walking_mean = np.mean(neural_df_s.iloc[walking_state.index.get_level_values(level=1)][neuron])\n",
    "        walking_std= np.std(neural_df_s.iloc[walking_state.index.get_level_values(level=1)][neuron])\n",
    "        walking_means.append(walking_mean)\n",
    "        walking_stds.append(walking_std)\n",
    "        anterior_grooming_mean = np.mean(neural_df_s.iloc[anterior_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        anterior_grooming_std = np.std(neural_df_s.iloc[anterior_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        anterior_grooming_means.append(anterior_grooming_mean)\n",
    "        anterior_grooming_stds.append(anterior_grooming_std)\n",
    "        antennal_grooming_mean = np.mean(neural_df_s.iloc[antennal_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        antennal_grooming_std = np.std(neural_df_s.iloc[antennal_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        antennal_grooming_means.append(antennal_grooming_mean)\n",
    "        antennal_grooming_stds.append(antennal_grooming_std)\n",
    "        foreleg_grooming_mean = np.mean(neural_df_s.iloc[foreleg_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        foreleg_grooming_std = np.std(neural_df_s.iloc[foreleg_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        foreleg_grooming_means.append(foreleg_grooming_mean)\n",
    "        foreleg_grooming_stds.append(foreleg_grooming_std)\n",
    "        abdominal_grooming_mean = np.mean(neural_df_s.iloc[abdominal_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        abdominal_grooming_std = np.std(neural_df_s.iloc[abdominal_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        abdominal_grooming_means.append(abdominal_grooming_mean)\n",
    "        abdominal_grooming_stds.append(abdominal_grooming_std)\n",
    "        abdominal_pushing_mean = np.mean(neural_df_s.iloc[abdominal_pushing_state.index.get_level_values(level=1)][neuron])\n",
    "        abdominal_pushing_std = np.std(neural_df_s.iloc[abdominal_pushing_state.index.get_level_values(level=1)][neuron])\n",
    "        abdominal_pushing_means.append(abdominal_pushing_mean)\n",
    "        abdominal_pushing_stds.append(abdominal_pushing_std)\n",
    "        posterior_grooming_mean = np.mean(neural_df_s.iloc[posterior_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        posterior_grooming_std = np.std(neural_df_s.iloc[posterior_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        posterior_grooming_means.append(posterior_grooming_mean)\n",
    "        posterior_grooming_stds.append(posterior_grooming_std)\n",
    "        hindleg_grooming_mean = np.mean(neural_df_s.iloc[hindleg_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        hindleg_grooming_std = np.std(neural_df_s.iloc[hindleg_grooming_state.index.get_level_values(level=1)][neuron])\n",
    "        hindleg_grooming_means.append(hindleg_grooming_mean)\n",
    "        hindleg_grooming_stds.append(hindleg_grooming_std)\n",
    "        \n",
    "plt.figure(figsize=(16,10))\n",
    "plt.boxplot([resting_means, walking_means, anterior_grooming_means,antennal_grooming_means, foreleg_grooming_means, \\\n",
    "             abdominal_grooming_means,abdominal_pushing_means,posterior_grooming_means,hindleg_grooming_means])\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7,8,9], states.tolist())\n",
    "plt.ylabel(\"mean $\\% \\Delta F/F$ neuron\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2745cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will also create a DataFrame with the results of the Tukey test\n",
    "columns = ['ab_g', 'ab_p', 'al_g', 'ar_g', 'f_g', 'h_g', 'p_g', 'r', 'w']\n",
    "tukey_df = pd.DataFrame(data = tukey_test, columns=list(combinations(columns, 2)))\n",
    "\"\"\"    \n",
    "                                                                        reject\n",
    "A results of ’reject = True’ means that a significant difference has been observed.\n",
    "abdominal_grooming  abdominal_pushing   0.1539    0.9 -0.2159  0.5238  False\n",
    "abdominal_grooming  antennal_grooming    0.267 0.5477 -0.1508  0.6849  False\n",
    "abdominal_grooming  anterior_grooming   0.0441    0.9 -0.3184  0.4067  False\n",
    "abdominal_grooming   foreleg_grooming   0.4392 0.0145  0.0483    0.83   True\n",
    "abdominal_grooming   hindleg_grooming  -0.2284    0.9 -2.1849   1.728  False\n",
    "abdominal_grooming posterior_grooming   0.4429 0.0138  0.0504  0.8354   True\n",
    "abdominal_grooming            resting  -0.5252  0.001 -0.8859 -0.1644   True\n",
    "abdominal_grooming            walking   0.5014  0.001  0.1408  0.8621   True\n",
    " abdominal_pushing  antennal_grooming   0.1131 0.8156 -0.1146  0.3408  False\n",
    " abdominal_pushing  anterior_grooming  -0.1098 0.0081 -0.2032 -0.0165   True\n",
    " abdominal_pushing   foreleg_grooming   0.2852  0.001  0.1118  0.4586   True\n",
    " abdominal_pushing   hindleg_grooming  -0.3824    0.9 -2.3072  1.5424  False\n",
    " abdominal_pushing posterior_grooming    0.289  0.001  0.1119   0.466   True\n",
    " abdominal_pushing            resting  -0.6791  0.001 -0.7651 -0.5931   True\n",
    " abdominal_pushing            walking   0.3475  0.001  0.2617  0.4333   True\n",
    " antennal_grooming  anterior_grooming  -0.2229 0.0364 -0.4386 -0.0073   True\n",
    " antennal_grooming   foreleg_grooming   0.1721 0.5071 -0.0884  0.4326  False\n",
    " antennal_grooming   hindleg_grooming  -0.4955    0.9 -2.4301  1.4391  False\n",
    " antennal_grooming posterior_grooming   0.1758 0.4917 -0.0871  0.4388  False\n",
    " antennal_grooming            resting  -0.7922  0.001 -1.0048 -0.5796   True\n",
    " antennal_grooming            walking   0.2344 0.0181  0.0219  0.4469   True\n",
    " anterior_grooming   foreleg_grooming   0.3951  0.001  0.2378  0.5523   True\n",
    " anterior_grooming   hindleg_grooming  -0.2726    0.9  -2.196  1.6509  False\n",
    " anterior_grooming posterior_grooming   0.3988  0.001  0.2375  0.5601   True\n",
    " anterior_grooming            resting  -0.5693  0.001 -0.6146 -0.5239   True\n",
    " anterior_grooming            walking   0.4573  0.001  0.4124  0.5023   True\n",
    "   foreleg_grooming   hindleg_grooming  -0.6676    0.9 -2.5966  1.2614  False\n",
    "  foreleg_grooming posterior_grooming   0.0037    0.9 -0.2139  0.2214  False\n",
    "  foreleg_grooming            resting  -0.9643  0.001 -1.1173 -0.8113   True\n",
    "  foreleg_grooming            walking   0.0623    0.9 -0.0906  0.2152  False\n",
    "  hindleg_grooming posterior_grooming   0.6713    0.9  -1.258  2.6006  False\n",
    "  hindleg_grooming            resting  -0.2967    0.9 -2.2198  1.6264  False\n",
    "  hindleg_grooming            walking   0.7299    0.9 -1.1932   2.653  False\n",
    "posterior_grooming            resting   -0.968  0.001 -1.1252 -0.8109   True\n",
    "posterior_grooming            walking   0.0586    0.9 -0.0985  0.2156  False\n",
    "           resting            walking   1.0266  0.001  1.0001  1.0531   True\n",
    "\"\"\"\n",
    "tukey_df[('ab_g', 'ab_p')] #To test behavior\n",
    "tukey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41fced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the neurons with significal difference between resting and walking\n",
    "tukey_df[tukey_df[('r', 'w')]==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEt's plot a matrix with the neurons and their value for behavior\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.matshow([resting_means, walking_means, anterior_grooming_means,antennal_grooming_means,foreleg_grooming_means, \\\n",
    "             abdominal_grooming_means,abdominal_pushing_means,posterior_grooming_means,hindleg_grooming_means], fignum=1, aspect='auto')\n",
    "plt.yticks([0, 1, 2, 3, 4, 5, 6,7,8], states.tolist())\n",
    "plt.xlabel(\"neurons number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac957a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now find all neurons that are significant for one behavior to all other behaviors\n",
    "all_true_neurons = []\n",
    "for i, neuron in tukey_df.iterrows() : \n",
    "    for column in columns :\n",
    "        cols = [col for col in neuron.index if column in col]\n",
    "        boolean = all(neuron[cols].values)\n",
    "        if boolean : all_true_neurons.append({'neuron_'+str(neuron.name) : column})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d866fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we looked for significance with walking behavior \n",
    "neurons_walking = []\n",
    "for i, neuron in tukey_df.iterrows() : \n",
    "    for column in columns :\n",
    "        if column == 'w' :\n",
    "            cols = [col for col in neuron.index if column in col]\n",
    "            count_true = 0\n",
    "            false = \"\"\n",
    "            for i in range(len(neuron[cols].values)) :\n",
    "                if neuron[cols].values[i] : count_true = count_true + 1\n",
    "                else : false = cols[i][0]\n",
    "            if count_true >6 : neurons_walking.append({'neuron_'+str(neuron.name) : column+\" \"+false})\n",
    "neurons_walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_behavior(neural_df, behavior_given) :\n",
    "    # function to plot background behavior activity\n",
    "    res = []\n",
    "    for behavior in neural_df['Manual'] :\n",
    "        if behavior == behavior_given : res.append(400)\n",
    "        else : res.append(0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90917c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot neurons that are involved in the resting state\n",
    "for i in range(12):\n",
    "    neuron_2 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_2\"]-610)/610\n",
    "    neuron_62 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_62\"]-610)/610\n",
    "    neuron_80 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_80\"]-610)/610\n",
    "    neuron_81 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_81\"]-610)/610\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(9.5, 5))\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_2, label=\"neuron 2\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_62, label=\"neuron 62\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_80, label=\"neuron 80\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_81, label=\"neuron 81\")\n",
    "    ax.fill_between(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], 0, find_behavior(neural_df_s[i*4040:i*4040+4040], 'resting'), facecolor='orange', alpha=0.5)\n",
    "    ax.set_xlabel(\"t (s)\")\n",
    "    ax.set_ylabel(\"$\\% \\Delta F/F$\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax.spines['left'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the right spine/ticks\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    # set the y-spine\n",
    "    ax.spines['bottom'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the top spine/ticks\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.title(f'Trial {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d733fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot neurons that are involved in the foreleg_grooming state\n",
    "for i in range(12):\n",
    "    neuron_25 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_25\"]-610)/610\n",
    "    neuron_36 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_36\"]-610)/610\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(9.5, 5))\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_25, label=\"neuron 25\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_36, label=\"neuron 36\")\n",
    "    ax.fill_between(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], 0, find_behavior(neural_df_s[i*4040:i*4040+4040], 'foreleg_grooming'), facecolor='orange')\n",
    "    ax.set_xlabel(\"t (s)\")\n",
    "    ax.set_ylabel(\"$\\% \\Delta F/F$\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax.spines['left'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the right spine/ticks\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    # set the y-spine\n",
    "    ax.spines['bottom'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the top spine/ticks\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.title(f'Trial {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12052d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot neurons that are involved in the abdominal_pushing state\n",
    "for i in range(12):\n",
    "    neuron_42 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_42\"]-610)/610\n",
    "    neuron_71 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_71\"]-610)/610\n",
    "    neuron_78 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_78\"]-610)/610\n",
    "    neuron_86 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_86\"]-610)/610\n",
    "    neuron_109 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_109\"]-610)/610\n",
    "    neuron_122 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_122\"]-610)/610\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(9.5, 5))\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_42, label=\"neuron 42\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_71, label=\"neuron 71\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_78, label=\"neuron 78\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_86, label=\"neuron 86\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_109, label=\"neuron 109\")\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_122, label=\"neuron 122\")\n",
    "    ax.fill_between(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], 0, find_behavior(neural_df_s[i*4040:i*4040+4040], 'abdominal_pushing'), facecolor='orange')\n",
    "    ax.set_xlabel(\"t (s)\")\n",
    "    ax.set_ylabel(\"$\\% \\Delta F/F$\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax.spines['left'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the right spine/ticks\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    # set the y-spine\n",
    "    ax.spines['bottom'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the top spine/ticks\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.title(f'Trial {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot neurons that are involved in the antennal_grooming state\n",
    "for i in range(12):\n",
    "    neuron_113 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_113\"]-610)/610\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(9.5, 5))\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_113, label=\"neuron 113\")\n",
    "    ax.fill_between(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], 0, find_behavior(neural_df_s[i*4040:i*4040+4040], 'antennal_grooming'), facecolor='orange')\n",
    "    ax.set_xlabel(\"t (s)\")\n",
    "    ax.set_ylabel(\"$\\% \\Delta F/F$\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax.spines['left'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the right spine/ticks\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    # set the y-spine\n",
    "    ax.spines['bottom'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the top spine/ticks\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.title(f'Trial {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac523a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot neuron 122 with 2 behaviors \n",
    "for i in range(12):\n",
    "    neuron_122 = 100*(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, i), \"neuron_122\"]-610)/610\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(9.5, 5))\n",
    "    ax.plot(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], neuron_122, label=\"neuron 122\")\n",
    "    ax.fill_between(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], 0, find_behavior(neural_df_s[i*4040:i*4040+4040], 'abdominal_pushing'), facecolor='orange')\n",
    "    ax.fill_between(neural_data_filtered.loc[(210301, \"J1xCI9\", 1, 0), \"t\"], 0, find_behavior(neural_df_s[i*4040:i*4040+4040], 'abdominal_grooming'), facecolor='blue')\n",
    "    ax.set_xlabel(\"t (s)\")\n",
    "    ax.set_ylabel(\"$\\% \\Delta F/F$\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax.spines['left'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the right spine/ticks\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    # set the y-spine\n",
    "    ax.spines['bottom'].set_position(('outward', 3))  # ('axes', -0.02))  # 'zero'\n",
    "\n",
    "    # turn off the top spine/ticks\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.title(f'Trial {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53152e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're computing the spearman correlation for each of the neuron with each of the joint to see whether specific\n",
    "# neuron trigger specific angles.\n",
    "\n",
    "pos_spearman_corr = []\n",
    "neg_spearman_corr = []\n",
    "for neuron in neural_df_s.columns : \n",
    "    if neuron == 't' : pass\n",
    "    else : \n",
    "        for angle in behav_data_r.filter(regex=\"angle\") : \n",
    "            spearman = spearmanr(neural_df_s[neuron], behav_data_r[angle])\n",
    "            if (spearman[1]<0.05) & (spearman[0]>0.5) :\n",
    "                pos_spearman_corr.append([neuron, angle, spearman])\n",
    "            elif (spearman[1]<0.05) & (spearman[0]<-0.5) :\n",
    "                neg_spearman_corr.append([neuron, angle, spearman])\n",
    "print(f'Positive Spearman correlation : {pos_spearman_corr}')\n",
    "print(f'Negative Spearman correlation :{neg_spearman_corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12aa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do now a scatter plot between the neurons and angles that have a significant correlation\n",
    "for pair in pos_spearman_corr :\n",
    "    plt.scatter(neural_df_s[pair[0]], behav_data_r[pair[1]])\n",
    "    plt.xlabel(pair[0])\n",
    "    plt.ylabel(pair[1])\n",
    "    plt.title('Spearman positive correlation')\n",
    "    plt.show()\n",
    "for pair in neg_spearman_corr :\n",
    "    plt.scatter(neural_df_s[pair[0]], behav_data_r[pair[1]])\n",
    "    plt.xlabel(pair[0])\n",
    "    plt.ylabel(pair[1])\n",
    "    plt.title('Spearman negative correlation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038f2a1",
   "metadata": {},
   "source": [
    "### Identifying correlations of low-dimensional signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525621b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behaviour_data_reduced : \n",
    "# size : (48480*143)\n",
    "\n",
    "label_dictionary = {'resting':0, 'walking':1, 'anterior_grooming':2, 'antennal_grooming':3, 'foreleg_grooming':4, 'abdominal_grooming':5, 'abdominal_pushing':6, 'posterior_grooming':7, 'hindleg_grooming':8}\n",
    "labels = behav_data_r[\"Manual\"].map(label_dictionary).to_numpy()\n",
    "colors = ['#0072BD', '#D95319', '#EDB120', '#7E2F8E', '#77AC30', '#4DBEEE', '#A2142F', '#000000', '#1e591e']\n",
    "\n",
    "labels_reduced = np.copy(labels)\n",
    "labels_reduced[labels_reduced>2] = 2\n",
    "colors_reduced = ['#0072BD', '#D95319', '#EDB120']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ac5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 : (n_samples, n_features)\n",
    "# size : (48480*123)\n",
    "# 123 components\n",
    "# 48480 samples\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "scat = ax.scatter(X1[:,0], X1[:,1], s=0.4, c=labels, cmap=mpl.colors.ListedColormap(colors))\n",
    "ax.set_xlabel(\"Component 0 [-]\")\n",
    "ax.set_ylabel(\"Component 1 [-]\")\n",
    "ax.set_title(f\"Class-coded scatter-plot of the first two components of the PCA results\")\n",
    "\n",
    "cb = fig.colorbar(scat)\n",
    "loc = np.arange(0,max(labels),max(labels)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(list(label_dictionary.keys()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1787531",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "scat = ax.scatter(X1[:,0], X1[:,1], s=0.4, c=labels_reduced, cmap=mpl.colors.ListedColormap(colors_reduced))\n",
    "ax.set_xlabel(\"Component 0 [-]\")\n",
    "ax.set_ylabel(\"Component 1 [-]\")\n",
    "ax.set_title(f\"Class-coded scatter-plot of the first two components of the PCA results\")\n",
    "\n",
    "cb = fig.colorbar(scat)\n",
    "loc = np.arange(0,max(labels_reduced),max(labels_reduced)/float(len(colors_reduced)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(['resting', 'walking', 'grooming'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y1 :\n",
    "# size : (48480*2)\n",
    "# 48480 samples\n",
    "# 2 components\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "scat = ax.scatter(Y1[:,0], Y1[:,1], s=0.4, c=labels, cmap=mpl.colors.ListedColormap(colors))\n",
    "ax.set_xlabel(\"Component 0 [-]\")\n",
    "ax.set_ylabel(\"Component 1 [-]\")\n",
    "ax.set_title(f\"Class-coded scatter-plot of the first two components of the PCA results\")\n",
    "\n",
    "cb = fig.colorbar(scat)\n",
    "loc = np.arange(0,max(labels),max(labels)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(list(label_dictionary.keys()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,12))\n",
    "scat = ax.scatter(Y1[:,0], Y1[:,1], s=0.4, c=labels_reduced, cmap=mpl.colors.ListedColormap(colors_reduced))\n",
    "ax.set_xlabel(\"Component 0 [-]\")\n",
    "ax.set_ylabel(\"Component 1 [-]\")\n",
    "ax.set_title(f\"Class-coded scatter-plot of the first two components of the PCA results\")\n",
    "\n",
    "cb = fig.colorbar(scat)\n",
    "loc = np.arange(0,max(labels_reduced),max(labels_reduced)/float(len(colors_reduced)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(['resting', 'walking', 'grooming'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24357b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-variate regression model\n",
    "# regressors: binary behavioural variables (i.e., walking yes/no, grooming yes/no, ...)\n",
    "# output: neuronal activity (possibly standardised)\n",
    "MVA_regressors = np.identity(9)[labels]\n",
    "MVA_output = neural_data.to_numpy()[:,1:]\n",
    "MVA_score = np.zeros(123)\n",
    "\n",
    "for i in range(123):\n",
    "    reg = LinearRegression().fit(MVA_regressors,MVA_output[:,i])\n",
    "    MVA_score[i] = reg.score(MVA_regressors, MVA_output[:,0])\n",
    "\n",
    "print(f\"Maximum explained variance with MVA : {max(MVA_score):2.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99362d4",
   "metadata": {},
   "source": [
    "## Classifying behaviour from neuronal activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "nb_trials = 12\n",
    "neurons_data_manual = neural_df_s.loc[(210301, \"J1xCI9\", 1), \"Manual\"].to_numpy()\n",
    "neurons_data = neural_df_s.loc[(210301, \"J1xCI9\", 1)].to_numpy()[:,1:-1]\n",
    "neuron_data_nb = np.zeros((123,48480))\n",
    "for i in range(123):\n",
    "    neuron_data_nb[i,:] = neural_df_s.loc[(210301, \"J1xCI9\", 1), \"neuron_\"+ str(i)].to_numpy()\n",
    "\n",
    "# Labeling\n",
    "walking_yn = np.zeros(48480)\n",
    "label = np.zeros(48480)\n",
    "\n",
    "for k in range(48480):\n",
    "    if neurons_data_manual[k] == \"walking\":\n",
    "        walking_yn[k] = 1\n",
    "        label[k] = 1\n",
    "    if neurons_data_manual[k] == \"abdominal_pushing\":\n",
    "        label[k] = 2\n",
    "    if neurons_data_manual[k] == \"anterior_grooming\":\n",
    "        label[k] = 3\n",
    "    if neurons_data_manual[k] == \"posterior_grooming\":\n",
    "        label[k] = 4\n",
    "    if neurons_data_manual[k] == \"foreleg_grooming\":\n",
    "        label[k] = 5\n",
    "    if neurons_data_manual[k] == \"abdominal_grooming\":\n",
    "        label[k] = 6\n",
    "    if neurons_data_manual[k] == \"hindleg_grooming\":\n",
    "        label[k] = 7\n",
    "    if neurons_data_manual[k] == \"antennal_grooming\":\n",
    "        label[k] = 8\n",
    "    \n",
    "# Data for trainning\n",
    "X_train, X_test, y_train, y_test = train_test_split(neurons_data, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5bfdb",
   "metadata": {},
   "source": [
    "### Predicting one behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468442f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression on all trials with each neuron at time on walking yes/no\n",
    "score_all_neuron = np.zeros(123)\n",
    "for i in range(123):\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(neuron_data_nb[i,:].reshape(-1, 1), walking_yn)\n",
    "    score_all_neuron[i] = logisticRegr.score(neuron_data_nb[i,:].reshape(-1, 1), walking_yn)\n",
    "print(f\"Best neurons : {np.argsort(score_all_neuron)[::-1][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for the 40 first neuron\n",
    "score_all_neuron[np.argsort(score_all_neuron)[::-1][:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for neuron found with logistic regression with only walking\n",
    "plot_neuron_data(np.argsort(score_all_neuron)[::-1], 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression on all trials with all neuron on walking yes/no\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(neurons_data, walking_yn, test_size=0.2)\n",
    "logisticRegr = LogisticRegression(max_iter=2000)\n",
    "logisticRegr.fit(X_train_2, y_train_2)\n",
    "score = logisticRegr.score(X_test_2, y_test_2)\n",
    "score = \"{:.4f}\".format(score)\n",
    "print(f\"Score with it self : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb47f2e",
   "metadata": {},
   "source": [
    "### Predicting all behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20201b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression  for all neuron all class\n",
    "logisticRegr = LogisticRegression(max_iter=2000)\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "score = logisticRegr.score(X_test, y_test)\n",
    "score = \"{:.4f}\".format(score)\n",
    "print(f\"Score with it self : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient analysis for logistic regression\n",
    "logisticRegr.coef_.shape\n",
    "nb_neuron_importance = 10\n",
    "\n",
    "for i in range(logisticRegr.coef_.shape[0]):\n",
    "    print(f\"For {i}\")\n",
    "    feature = logisticRegr.coef_[i,:]\n",
    "    sort_feature = np.argsort(feature)[::-1][:nb_neuron_importance]\n",
    "    print(f\"{nb_neuron_importance} important Neuron for the random forest\")\n",
    "    for j in range(nb_neuron_importance):\n",
    "        print(f\"Neuron : {sort_feature[j]}\")\n",
    "    #Plot for neuron found with logistic regression \n",
    "    plot_neuron_data(sort_feature, 2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99207fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"score : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature analysis for random forest\n",
    "nb_neuron_importance = 10\n",
    "feature = np.argsort(clf.feature_importances_)[::-1][:nb_neuron_importance]\n",
    "print(f\"{nb_neuron_importance} important Neuron for the random forest\")\n",
    "for i in range(nb_neuron_importance):\n",
    "    print(f\"Neuron : {feature[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6030606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for neuron found with random forest\n",
    "plot_neuron_data(feature, 2)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
